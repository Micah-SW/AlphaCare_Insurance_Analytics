{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff9ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom modules (DataLoader, EDAPlotter) imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Append the project root directory to the system path to import modules\n",
    "# The path is relative to the notebook's location in 'notebooks/'\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import custom modules\n",
    "from src.loader import DataLoader\n",
    "from src.eda_utils import EDAPlotter\n",
    "\n",
    "print(\"Custom modules (DataLoader, EDAPlotter) imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc675ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded. Shape: (1000098, 52)\n",
      "\n",
      "--- Data Quality Check ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000098 entries, 0 to 1000097\n",
      "Columns: 52 entries, underwrittencoverid to totalclaims\n",
      "dtypes: bool(1), category(36), float64(11), int64(4)\n",
      "memory usage: 152.7 MB\n",
      "\n",
      "Top 5 Missing Columns:\n",
      "numberofvehiclesinfleet    1000098\n",
      "crossborder                 999400\n",
      "customvalueestimate         779642\n",
      "rebuilt                     641901\n",
      "converted                   641901\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and Load Data (The DVC-tracked file)\n",
    "loader = DataLoader('../data/raw/insurance_claims.csv')\n",
    "df = loader.load_data()\n",
    "df = loader.clean_column_names()\n",
    "df = loader.optimize_dtypes()\n",
    "\n",
    "print(f\"Data successfully loaded. Shape: {df.shape}\")\n",
    "print(\"\\n--- Data Quality Check ---\")\n",
    "# Print a concise summary of column types and memory usage\n",
    "df.info(verbose=False, memory_usage=\"deep\")\n",
    "print(\"\\nTop 5 Missing Columns:\")\n",
    "# Identify critical missing data points for your interim report\n",
    "print(df.isnull().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b986c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionMonth Dtype after fix: category\n",
      "\n",
      "Loss Ratio calculated.\n",
      "Mean Loss Ratio (Profitability Indicator): 0.2164\n",
      "Max Capped Loss Ratio: 5.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14773/3005280302.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['loss_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# In Cell 3: Feature Engineering (The KPI Metric)\n",
    "\n",
    "# CRITICAL FIX: Ensure 'transactionmonth' is the correct datetime type, overriding any previous type issues.\n",
    "if 'transactionmonth' in df.columns:\n",
    "    # Coercing errors will turn invalid date strings into NaT (Not a Time)\n",
    "    df['transactionmonth'] = pd.to_datetime(df['transactionmonth'], errors='coerce')\n",
    "    # Drop any rows where the date failed to parse (safeguards against resample issues)\n",
    "    df.dropna(subset=['transactionmonth'], inplace=True)\n",
    "    \n",
    "    # DIAGNOSTIC CHECK: Print the type to confirm the fix\n",
    "    print(f\"TransactionMonth Dtype after fix: {df['transactionmonth'].dtype}\")\n",
    "\n",
    "\n",
    "# Calculate the industry-standard KPI: LOSS RATIO\n",
    "# Loss Ratio = Total Claims / Total Premium\n",
    "df['loss_ratio'] = df['totalclaims'] / df['totalpremium']\n",
    "\n",
    "# CRITICAL DATA CLEANING: Handle division by zero/NaN/Inf values.\n",
    "df['loss_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df['loss_ratio'] = df['loss_ratio'].fillna(0) \n",
    "\n",
    "# Cap the loss ratio for robust visualization. Loss Ratio > 1.0 means unprofitable.\n",
    "df['capped_loss_ratio'] = df['loss_ratio'].clip(upper=5.0) \n",
    "\n",
    "print(f\"\\nLoss Ratio calculated.\")\n",
    "print(f\"Mean Loss Ratio (Profitability Indicator): {df['loss_ratio'].mean():.4f}\")\n",
    "print(f\"Max Capped Loss Ratio: {df['capped_loss_ratio'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "701c9d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 4: Univariate plots generated and saved to reports/figures/\n"
     ]
    }
   ],
   "source": [
    "plotter = EDAPlotter(df)\n",
    "\n",
    "# Check distribution of the core money variables\n",
    "plotter.plot_univariate_distribution(column='totalpremium', title_suffix=\"($) - Skewed\")\n",
    "plotter.plot_univariate_distribution(column='totalclaims', title_suffix=\"($) - Heavy Right Tail\")\n",
    "\n",
    "# Plot the engineered KPI metric\n",
    "plotter.plot_univariate_distribution(column='capped_loss_ratio', title_suffix=\" (Capped at 5.0)\")\n",
    "\n",
    "print(\"Cell 4: Univariate plots generated and saved to reports/figures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6d36e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sovereign/AlphaCare_Insurance_Analytics/src/eda_utils.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  risk_df = self.df.groupby(x_col)[y_col].mean().reset_index()\n",
      "/home/sovereign/AlphaCare_Insurance_Analytics/src/eda_utils.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  risk_df = self.df.groupby(x_col)[y_col].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 5: Bivariate plots generated and saved to reports/figures/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sovereign/AlphaCare_Insurance_Analytics/src/eda_utils.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  risk_df = self.df.groupby(x_col)[y_col].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Insight 1: Geography (Province) vs. Profitability (Loss Ratio)\n",
    "plotter.plot_risk_by_category(x_col='province', y_col='loss_ratio', sort=True)\n",
    "\n",
    "# Insight 2: Vehicle Body Type vs. Claim Severity (totalclaims)\n",
    "plotter.plot_risk_by_category(x_col='bodytype', y_col='totalclaims', sort=True)\n",
    "\n",
    "# Insight 3: Demographics (Marital Status) vs. Loss Ratio\n",
    "plotter.plot_risk_by_category(x_col='maritalstatus', y_col='loss_ratio', sort=True)\n",
    "\n",
    "print(\"Cell 5: Bivariate plots generated and saved to reports/figures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32807280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Time series created using categorical datetime extraction\n",
      "‚úì Time series plot generated and saved to reports/figures/claims_time_series.png\n",
      "‚úì Data points: 23 months from 2013-10-31 00:00:00 to 2015-08-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# In Cell 6: Correlation and Time Series - FINAL SOLUTION\n",
    "\n",
    "# 6.1 Correlation Matrix\n",
    "numerical_cols = [\n",
    "    'totalpremium', \n",
    "    'totalclaims', \n",
    "    'loss_ratio', \n",
    "    'customvalueestimate', \n",
    "    'registrationyear',    \n",
    "    'cylinders',           \n",
    "    'termfrequency'        \n",
    "]\n",
    "plotter.plot_correlation_heatmap(numerical_cols)\n",
    "\n",
    "# 6.2 Time Series of Claims (Creative Plotting)\n",
    "# FINAL SOLUTION: Convert categorical datetime to regular datetime\n",
    "\n",
    "# Method 1: Extract datetime from categorical (most reliable)\n",
    "# Since the categories are already datetime64[ns], we can convert them directly\n",
    "try:\n",
    "    # Extract the datetime values from the categorical\n",
    "    # Convert categorical to its underlying datetime categories\n",
    "    datetime_values = df['transactionmonth'].cat.categories[df['transactionmonth'].cat.codes]\n",
    "    \n",
    "    # Create a new DataFrame with proper datetime\n",
    "    df_time = df.copy()\n",
    "    df_time['transactionmonth'] = pd.DatetimeIndex(datetime_values)\n",
    "    \n",
    "    # Drop any NaT values (just in case)\n",
    "    df_time = df_time.dropna(subset=['transactionmonth'])\n",
    "    \n",
    "    # Set index and resample - use 'ME' (Month End) instead of deprecated 'M'\n",
    "    time_series_df = df_time.set_index('transactionmonth').resample('ME')['totalclaims'].sum().reset_index()\n",
    "    \n",
    "    print(\"‚úì Time series created using categorical datetime extraction\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Method 1 failed: {e}\")\n",
    "    \n",
    "    # Method 2: Fallback - convert to string then to datetime\n",
    "    df_time = df.copy()\n",
    "    # Convert categorical to string then to datetime\n",
    "    df_time['transactionmonth'] = pd.to_datetime(df_time['transactionmonth'].astype(str), errors='coerce')\n",
    "    df_time = df_time.dropna(subset=['transactionmonth'])\n",
    "    \n",
    "    # Set index and resample\n",
    "    time_series_df = df_time.set_index('transactionmonth').resample('ME')['totalclaims'].sum().reset_index()\n",
    "    \n",
    "    print(\"‚úì Time series created using string conversion fallback\")\n",
    "\n",
    "# Generate the plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(x='transactionmonth', y='totalclaims', data=time_series_df, marker='o', color=sns.color_palette(\"viridis\")[3])\n",
    "plt.title('Monthly Total Claims Over Time', fontsize=16)\n",
    "plt.xlabel(\"Month\", fontsize=12)\n",
    "plt.ylabel(\"Total Claims (USD)\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../reports/figures/claims_time_series.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"‚úì Time series plot generated and saved to reports/figures/claims_time_series.png\")\n",
    "print(f\"‚úì Data points: {len(time_series_df)} months from {time_series_df['transactionmonth'].min()} to {time_series_df['transactionmonth'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0509e66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating all missing visualizations and tables...\n",
      "\n",
      "1. Generating Province Risk Distribution...\n",
      "   ‚úì Saved to ../reports/figures/province_risk_dist.png\n",
      "\n",
      "2. Generating Vehicle Type Risk Distribution...\n",
      "   ‚úì Saved to ../reports/figures/vehicle_type_risk.png\n",
      "\n",
      "3. Generating Correlation Heatmap...\n",
      "   ‚úì Saved to ../reports/figures/correlation_heatmap.png\n",
      "\n",
      "4. Generating Statistical Tables...\n",
      "\n",
      "================================================================================\n",
      "TABLE 1: Descriptive Statistics of Core Financial Metrics\n",
      "================================================================================\n",
      "|       |   totalpremium |     totalclaims |    loss_ratio |\n",
      "|:------|---------------:|----------------:|--------------:|\n",
      "| count |     1.0001e+06 |      1.0001e+06 |    1.0001e+06 |\n",
      "| mean  |    61.91       |     64.86       |    0.22       |\n",
      "| std   |   230.28       |   2384.07       |    7.3        |\n",
      "| min   |  -782.58       | -12002.4        |  -18.7        |\n",
      "| 25%   |     0          |      0          |    0          |\n",
      "| 50%   |     2.18       |      0          |    0          |\n",
      "| 75%   |    21.93       |      0          |    0          |\n",
      "| max   | 65282.6        | 393092          | 2553.6        |\n",
      "\n",
      "‚úì Saved to reports/tables/descriptive_stats.csv\n",
      "\n",
      "================================================================================\n",
      "TABLE 2: Feature Correlations with Loss Ratio\n",
      "================================================================================\n",
      "| Feature       |   Correlation with Loss Ratio | Strength   | Direction   |\n",
      "|:--------------|------------------------------:|:-----------|:------------|\n",
      "| kilowatts     |                         0.003 | Weak       | Positive    |\n",
      "| numberofdoors |                         0.003 | Weak       | Positive    |\n",
      "| postalcode    |                        -0.003 | Weak       | Negative    |\n",
      "| cylinders     |                         0.002 | Weak       | Positive    |\n",
      "| mmcode        |                        -0.001 | Weak       | Negative    |\n",
      "\n",
      "‚úì Saved to reports/tables/loss_ratio_correlations.csv\n",
      "\n",
      "================================================================================\n",
      "TABLE 3: Top 5 Highest Risk Provinces (Minimum 100 policies)\n",
      "================================================================================\n",
      "| Province     |   Mean Loss Ratio | Policy Count   | Avg Premium per Policy   | Avg Claims per Policy   | Risk Tier        |\n",
      "|:-------------|------------------:|:---------------|:-------------------------|:------------------------|:-----------------|\n",
      "| Gauteng      |             0.262 | 393,865        | $61.07                   | $74.63                  | üü† Elevated Risk |\n",
      "| Limpopo      |             0.253 | 24,836         | $61.90                   | $40.93                  | üü† Elevated Risk |\n",
      "| Mpumalanga   |             0.236 | 52,718         | $53.80                   | $38.79                  | üü° Medium Risk   |\n",
      "| Western Cape |             0.194 | 170,796        | $57.42                   | $60.83                  | üü¢ Low Risk      |\n",
      "| North West   |             0.179 | 143,287        | $52.28                   | $41.32                  | üü¢ Low Risk      |\n",
      "\n",
      "‚úì Saved to reports/tables/top_risk_provinces.csv\n",
      "\n",
      "================================================================================\n",
      "TABLE 4: Vehicle Types by Risk Level (Top 6, Minimum 50 policies)\n",
      "================================================================================\n",
      "| Vehicle Type      |   Mean Loss Ratio | Policy Count   | Total Premium   | Total Claims   | Risk Level      |\n",
      "|:------------------|------------------:|:---------------|:----------------|:---------------|:----------------|\n",
      "| Heavy Commercial  |             0.457 | 7,401          | $460,948        | $750,475       | üî¥ Extreme Risk |\n",
      "| Light Commercial  |             0.365 | 3,897          | $260,498        | $60,452        | üü† High Risk    |\n",
      "| Medium Commercial |             0.306 | 53,985         | $3,922,746      | $4,119,867     | üü† High Risk    |\n",
      "| Passenger Vehicle |             0.209 | 933,598        | $56,642,017     | $59,372,070    | üü° Medium Risk  |\n",
      "| Bus               |             0     | 665            | $58,245         | $7,997         | üü¢ Low Risk     |\n",
      "\n",
      "‚úì Saved to reports/tables/vehicle_type_risk_table.csv\n",
      "\n",
      "================================================================================\n",
      "TABLE 5: Time Series Claims Summary (Oct 2013 - Aug 2015)\n",
      "================================================================================\n",
      "| Metric                 | Value       |\n",
      "|:-----------------------|:------------|\n",
      "| Total Months           | 23          |\n",
      "| Average Monthly Claims | $2,820,328  |\n",
      "| Minimum Monthly Claims | $0          |\n",
      "| Maximum Monthly Claims | $9,076,825  |\n",
      "| Standard Deviation     | $3,140,793  |\n",
      "| Total Claims Period    | $64,867,546 |\n",
      "\n",
      "‚úì Saved to reports/tables/time_series_summary.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ GENERATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìä VISUALIZATIONS GENERATED:\n",
      "  1. province_risk_dist.png       - Loss Ratio by Province (Top 10)\n",
      "  2. vehicle_type_risk.png        - Loss Ratio by Vehicle Type (Top 8)\n",
      "  3. correlation_heatmap.png      - Feature Correlation Matrix\n",
      "  4. claims_time_series.png       - Monthly Claims Time Series\n",
      "\n",
      "üìã TABLES GENERATED:\n",
      "  1. descriptive_stats.csv        - Core financial metrics\n",
      "  2. loss_ratio_correlations.csv  - Top feature correlations\n",
      "  3. top_risk_provinces.csv       - Highest risk provinces\n",
      "  4. vehicle_type_risk_table.csv  - Vehicle type risk analysis\n",
      "  5. time_series_summary.csv      - Time series statistics\n",
      "\n",
      "üìù INSTRUCTIONS:\n",
      "  1. Copy the markdown tables above into your report\n",
      "  2. Reference images in report: ![Description](reports/figures/filename.png)\n",
      "  3. Update figure numbers in report as needed\n",
      "  4. All files saved to 'reports/' directory\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE VISUALIZATION AND TABLE GENERATION - FINAL VERSION\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../reports/figures', exist_ok=True)\n",
    "os.makedirs('../reports/tables', exist_ok=True)\n",
    "\n",
    "print(\"Generating all missing visualizations and tables...\\n\")\n",
    "\n",
    "# 1. Generate Figure 3: Province Risk Distribution\n",
    "print(\"1. Generating Province Risk Distribution...\")\n",
    "try:\n",
    "    # Use observed=False to handle categorical grouping\n",
    "    grouped = df.groupby('province', observed=False)['loss_ratio'].agg(['mean', 'count', 'std']).reset_index()\n",
    "    grouped = grouped[grouped['count'] >= 10]  # At least 10 samples\n",
    "    grouped = grouped.sort_values('mean', ascending=False).head(10)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    colors = sns.color_palette(\"RdYlBu_r\", len(grouped))\n",
    "    bars = ax.bar(range(len(grouped)), grouped['mean'], color=colors, edgecolor='black')\n",
    "    \n",
    "    ax.set_title('Loss Ratio Distribution by Province (Top 10)', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Province', fontsize=12)\n",
    "    ax.set_ylabel('Mean Loss Ratio', fontsize=12)\n",
    "    ax.set_xticks(range(len(grouped)))\n",
    "    ax.set_xticklabels(grouped['province'], rotation=45, ha='right', fontsize=10)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (mean_val, count_val) in enumerate(zip(grouped['mean'], grouped['count'])):\n",
    "        ax.text(i, mean_val + (0.02 * max(grouped['mean'])), \n",
    "                f'{mean_val:.3f}\\n(n={count_val:,})', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Add horizontal line for overall mean\n",
    "    overall_mean = df['loss_ratio'].mean()\n",
    "    ax.axhline(y=overall_mean, color='red', linestyle='--', alpha=0.7, \n",
    "               label=f'Overall Mean: {overall_mean:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/province_risk_dist.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ‚úì Saved to ../reports/figures/province_risk_dist.png\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚úó Error: {e}\")\n",
    "\n",
    "# 2. Generate Figure 4: Vehicle Type Risk\n",
    "print(\"\\n2. Generating Vehicle Type Risk Distribution...\")\n",
    "try:\n",
    "    grouped = df.groupby('vehicletype', observed=False)['loss_ratio'].agg(['mean', 'count', 'std']).reset_index()\n",
    "    grouped = grouped[grouped['count'] >= 10]\n",
    "    grouped = grouped.sort_values('mean', ascending=False).head(8)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    colors = sns.color_palette(\"viridis\", len(grouped))\n",
    "    bars = ax.bar(range(len(grouped)), grouped['mean'], color=colors, edgecolor='black')\n",
    "    \n",
    "    ax.set_title('Loss Ratio by Vehicle Type (Top 8)', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Vehicle Type', fontsize=12)\n",
    "    ax.set_ylabel('Mean Loss Ratio', fontsize=12)\n",
    "    ax.set_xticks(range(len(grouped)))\n",
    "    ax.set_xticklabels(grouped['vehicletype'], rotation=45, ha='right', fontsize=10)\n",
    "    \n",
    "    for i, (mean_val, count_val) in enumerate(zip(grouped['mean'], grouped['count'])):\n",
    "        ax.text(i, mean_val + (0.02 * max(grouped['mean'])), \n",
    "                f'{mean_val:.3f}\\n(n={count_val:,})', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    overall_mean = df['loss_ratio'].mean()\n",
    "    ax.axhline(y=overall_mean, color='red', linestyle='--', alpha=0.7, \n",
    "               label=f'Overall Mean: {overall_mean:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/vehicle_type_risk.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ‚úì Saved to ../reports/figures/vehicle_type_risk.png\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚úó Error: {e}\")\n",
    "\n",
    "# 3. Generate Correlation Heatmap with only numeric columns\n",
    "print(\"\\n3. Generating Correlation Heatmap...\")\n",
    "try:\n",
    "    # Only use truly numeric columns\n",
    "    numeric_cols = ['totalpremium', 'totalclaims', 'loss_ratio', 'customvalueestimate', \n",
    "                    'registrationyear', 'cylinders', 'cubiccapacity', 'kilowatts']\n",
    "    \n",
    "    # Filter to columns that exist and are numeric\n",
    "    available_numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "    \n",
    "    # Check data types to ensure they're numeric\n",
    "    for col in available_numeric_cols:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            print(f\"   Warning: {col} is not numeric, removing from correlation\")\n",
    "            available_numeric_cols.remove(col)\n",
    "    \n",
    "    if len(available_numeric_cols) >= 2:\n",
    "        corr = df[available_numeric_cols].corr(numeric_only=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", \n",
    "                    linewidths=.5, linecolor='black', mask=mask,\n",
    "                    cbar_kws={\"shrink\": .8})\n",
    "        plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../reports/figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"   ‚úì Saved to ../reports/figures/correlation_heatmap.png\")\n",
    "    else:\n",
    "        print(\"   ‚úó Not enough numeric columns for correlation matrix\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚úó Error generating correlation heatmap: {e}\")\n",
    "\n",
    "# 4. GENERATE ALL STATISTICAL TABLES\n",
    "print(\"\\n4. Generating Statistical Tables...\")\n",
    "\n",
    "# Table 1: Descriptive Statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 1: Descriptive Statistics of Core Financial Metrics\")\n",
    "print(\"=\"*80)\n",
    "stats_df = df[['totalpremium', 'totalclaims', 'loss_ratio']].describe().round(2)\n",
    "print(stats_df.to_markdown())\n",
    "stats_df.to_csv('../reports/tables/descriptive_stats.csv')\n",
    "print(\"\\n‚úì Saved to reports/tables/descriptive_stats.csv\")\n",
    "\n",
    "# Table 2: Top 5 Feature Correlations with Loss Ratio\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 2: Feature Correlations with Loss Ratio\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate correlation with loss_ratio for all numeric columns\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'loss_ratio' in numeric_features:\n",
    "    numeric_features.remove('loss_ratio')\n",
    "    \n",
    "if numeric_features:\n",
    "    # Calculate correlations\n",
    "    correlations = {}\n",
    "    for feature in numeric_features[:10]:  # Limit to first 10 features for readability\n",
    "        if df[feature].notna().sum() > 100:  # Only if we have enough data\n",
    "            corr_value = df['loss_ratio'].corr(df[feature])\n",
    "            correlations[feature] = corr_value\n",
    "    \n",
    "    # Sort by absolute correlation\n",
    "    sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:5]\n",
    "    \n",
    "    # Create table\n",
    "    corr_table_data = []\n",
    "    for feature, corr_value in sorted_corr:\n",
    "        strength = \"Strong\" if abs(corr_value) > 0.5 else \"Moderate\" if abs(corr_value) > 0.3 else \"Weak\"\n",
    "        direction = \"Positive\" if corr_value > 0 else \"Negative\"\n",
    "        corr_table_data.append([feature, round(corr_value, 3), strength, direction])\n",
    "    \n",
    "    corr_df = pd.DataFrame(corr_table_data, \n",
    "                           columns=['Feature', 'Correlation with Loss Ratio', 'Strength', 'Direction'])\n",
    "    print(corr_df.to_markdown(index=False))\n",
    "    corr_df.to_csv('../reports/tables/loss_ratio_correlations.csv', index=False)\n",
    "    print(\"\\n‚úì Saved to reports/tables/loss_ratio_correlations.csv\")\n",
    "else:\n",
    "    print(\"No numeric features found for correlation analysis\")\n",
    "\n",
    "# Table 3: Top Risk Provinces\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 3: Top 5 Highest Risk Provinces (Minimum 100 policies)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "province_stats = df.groupby('province', observed=False).agg({\n",
    "    'loss_ratio': ['mean', 'count'],\n",
    "    'totalpremium': 'sum',\n",
    "    'totalclaims': 'sum'\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "province_stats.columns = ['mean_loss_ratio', 'policy_count', 'total_premium', 'total_claims']\n",
    "\n",
    "# Filter for meaningful sample sizes\n",
    "province_stats = province_stats[province_stats['policy_count'] >= 100]\n",
    "\n",
    "# Calculate additional metrics\n",
    "province_stats['avg_premium_per_policy'] = (province_stats['total_premium'] / province_stats['policy_count']).round(2)\n",
    "province_stats['avg_claims_per_policy'] = (province_stats['total_claims'] / province_stats['policy_count']).round(2)\n",
    "\n",
    "# Sort and get top 5\n",
    "top_provinces = province_stats.sort_values('mean_loss_ratio', ascending=False).head(5)\n",
    "\n",
    "# Create display table\n",
    "province_display = pd.DataFrame({\n",
    "    'Province': top_provinces.index,\n",
    "    'Mean Loss Ratio': top_provinces['mean_loss_ratio'].round(3),\n",
    "    'Policy Count': top_provinces['policy_count'].astype(int).apply(lambda x: f\"{x:,}\"),\n",
    "    'Avg Premium per Policy': top_provinces['avg_premium_per_policy'].apply(lambda x: f\"${x:,.2f}\"),\n",
    "    'Avg Claims per Policy': top_provinces['avg_claims_per_policy'].apply(lambda x: f\"${x:,.2f}\")\n",
    "})\n",
    "\n",
    "# Add risk tiers based on loss ratio\n",
    "risk_tiers = []\n",
    "for ratio in top_provinces['mean_loss_ratio']:\n",
    "    if ratio > 0.3:\n",
    "        risk_tiers.append('üî¥ High Risk')\n",
    "    elif ratio > 0.25:\n",
    "        risk_tiers.append('üü† Elevated Risk')\n",
    "    elif ratio > 0.2:\n",
    "        risk_tiers.append('üü° Medium Risk')\n",
    "    else:\n",
    "        risk_tiers.append('üü¢ Low Risk')\n",
    "\n",
    "province_display['Risk Tier'] = risk_tiers\n",
    "\n",
    "print(province_display.to_markdown(index=False))\n",
    "province_display.to_csv('../reports/tables/top_risk_provinces.csv', index=False)\n",
    "print(\"\\n‚úì Saved to reports/tables/top_risk_provinces.csv\")\n",
    "\n",
    "# Table 4: Vehicle Type Risk Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 4: Vehicle Types by Risk Level (Top 6, Minimum 50 policies)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vehicle_stats = df.groupby('vehicletype', observed=False).agg({\n",
    "    'loss_ratio': ['mean', 'count'],\n",
    "    'totalpremium': 'sum',\n",
    "    'totalclaims': 'sum'\n",
    "}).round(4)\n",
    "\n",
    "vehicle_stats.columns = ['mean_loss_ratio', 'policy_count', 'total_premium', 'total_claims']\n",
    "\n",
    "# Filter for meaningful sample sizes\n",
    "vehicle_stats = vehicle_stats[vehicle_stats['policy_count'] >= 50]\n",
    "\n",
    "# Sort and get top 6\n",
    "top_vehicles = vehicle_stats.sort_values('mean_loss_ratio', ascending=False).head(6)\n",
    "\n",
    "# Create display table\n",
    "vehicle_display = pd.DataFrame({\n",
    "    'Vehicle Type': top_vehicles.index,\n",
    "    'Mean Loss Ratio': top_vehicles['mean_loss_ratio'].round(3),\n",
    "    'Policy Count': top_vehicles['policy_count'].astype(int).apply(lambda x: f\"{x:,}\"),\n",
    "    'Total Premium': top_vehicles['total_premium'].apply(lambda x: f\"${x:,.0f}\"),\n",
    "    'Total Claims': top_vehicles['total_claims'].apply(lambda x: f\"${x:,.0f}\")\n",
    "})\n",
    "\n",
    "# Add risk levels\n",
    "risk_levels = []\n",
    "for ratio in top_vehicles['mean_loss_ratio']:\n",
    "    if ratio > 0.4:\n",
    "        risk_levels.append('üî¥ Extreme Risk')\n",
    "    elif ratio > 0.3:\n",
    "        risk_levels.append('üü† High Risk')\n",
    "    elif ratio > 0.2:\n",
    "        risk_levels.append('üü° Medium Risk')\n",
    "    else:\n",
    "        risk_levels.append('üü¢ Low Risk')\n",
    "\n",
    "vehicle_display['Risk Level'] = risk_levels\n",
    "\n",
    "print(vehicle_display.to_markdown(index=False))\n",
    "vehicle_display.to_csv('../reports/tables/vehicle_type_risk_table.csv', index=False)\n",
    "print(\"\\n‚úì Saved to reports/tables/vehicle_type_risk_table.csv\")\n",
    "\n",
    "# Table 5: Time Series Summary Statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 5: Time Series Claims Summary (Oct 2013 - Aug 2015)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate time series statistics if available\n",
    "if 'time_series_df' in locals() or 'time_series_df' in globals():\n",
    "    ts_stats = pd.DataFrame({\n",
    "        'Metric': ['Total Months', 'Average Monthly Claims', 'Minimum Monthly Claims', \n",
    "                   'Maximum Monthly Claims', 'Standard Deviation', 'Total Claims Period'],\n",
    "        'Value': [\n",
    "            len(time_series_df),\n",
    "            f\"${time_series_df['totalclaims'].mean():,.0f}\",\n",
    "            f\"${time_series_df['totalclaims'].min():,.0f}\",\n",
    "            f\"${time_series_df['totalclaims'].max():,.0f}\",\n",
    "            f\"${time_series_df['totalclaims'].std():,.0f}\",\n",
    "            f\"${time_series_df['totalclaims'].sum():,.0f}\"\n",
    "        ]\n",
    "    })\n",
    "    print(ts_stats.to_markdown(index=False))\n",
    "    ts_stats.to_csv('../reports/tables/time_series_summary.csv', index=False)\n",
    "    print(\"\\n‚úì Saved to reports/tables/time_series_summary.csv\")\n",
    "else:\n",
    "    print(\"Time series data not available for summary statistics\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ GENERATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìä VISUALIZATIONS GENERATED:\")\n",
    "print(\"  1. province_risk_dist.png       - Loss Ratio by Province (Top 10)\")\n",
    "print(\"  2. vehicle_type_risk.png        - Loss Ratio by Vehicle Type (Top 8)\")\n",
    "print(\"  3. correlation_heatmap.png      - Feature Correlation Matrix\")\n",
    "print(\"  4. claims_time_series.png       - Monthly Claims Time Series\")\n",
    "print(\"\\nüìã TABLES GENERATED:\")\n",
    "print(\"  1. descriptive_stats.csv        - Core financial metrics\")\n",
    "print(\"  2. loss_ratio_correlations.csv  - Top feature correlations\")\n",
    "print(\"  3. top_risk_provinces.csv       - Highest risk provinces\")\n",
    "print(\"  4. vehicle_type_risk_table.csv  - Vehicle type risk analysis\")\n",
    "print(\"  5. time_series_summary.csv      - Time series statistics\")\n",
    "print(\"\\nüìù INSTRUCTIONS:\")\n",
    "print(\"  1. Copy the markdown tables above into your report\")\n",
    "print(\"  2. Reference images in report: ![Description](reports/figures/filename.png)\")\n",
    "print(\"  3. Update figure numbers in report as needed\")\n",
    "print(\"  4. All files saved to 'reports/' directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
